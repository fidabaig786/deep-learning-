{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NoPtDOgQWLWh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "saNhJmTzWLWi",
    "outputId": "604bdb1f-a367-46f4-caa8-009e03b7da8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 14s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train) , (X_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_St6VI5SW7rj",
    "outputId": "35d15acf-819f-44ee-98f3-4848f81dd541"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HiYhR8HRW_Rc",
    "outputId": "9f3caa51-5a8f-4822-d557-1f4a73fc683e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6q7KAhFCWLWj"
   },
   "source": [
    "We now create a list of labels corresponding to the 10 categories.  It will be used to convert the 0-9 digits in the target arrays to string labels. The categories are labeled as follows:\n",
    "\n",
    "  0. airplane\n",
    "  1. automobile\n",
    "  2. bird\n",
    "  3. cat\n",
    "  4. deer\n",
    "  5. dog\n",
    "  6. frog\n",
    "  7. horse\n",
    "  8. ship\n",
    "  9. truck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xDQ94OJW6oU"
   },
   "outputs": [],
   "source": [
    "List=[\"Airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"sheep\",\"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4zkJxNvWLWj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gLrKBCsWLWj"
   },
   "source": [
    "**3) Normalize the image data from [0,255] to be [0,1].  Normalizing improves model training (to test this, you can comment out the normalization later).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-IyyX3ZWLWj"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7iOZn2yWLWk"
   },
   "source": [
    "**4) Convert the target arrays to one-hot encodings.  Hint: checkout the [`keras.utils.np_utils.to_categorical()`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2kM3L3yWLWk"
   },
   "outputs": [],
   "source": [
    "import keras as k\n",
    "y_train = k.utils.to_categorical(y_train)\n",
    "y_test = k.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFd_Y0xLWLWk"
   },
   "source": [
    "**5) Visualize some images in each category using the `imshow()` function in `matplotlib.pyplot`.  Can you recreate the figure below?  Hint: the below figure was created using the first 8 images belonging to each category in the training data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFXWiMN7WLWk"
   },
   "source": [
    "![Dataset.png](attachment:Dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "OzSwjr_YWLWk",
    "outputId": "8c531778-9628-47b0-9f92-b1c3c232812c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f68d96fdf40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "X6CRMw1RXY39",
    "outputId": "b0d3442d-c5ef-47ec-fa88-58714974ae2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f68d91de130>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJDCHc4EWLWl"
   },
   "source": [
    "<a id='first_model'></a>\n",
    "\n",
    "# 2 - First naive model\n",
    "\n",
    "In order to better understand the importance of CNNs, it is instructive to first see how well a naive dense network performs on the dataset.\n",
    "\n",
    "**6) Create a sequential model with 4 `Dense` hidden layers of 2048, 1024, 512, and 256 nodes each, with ReLU activation, and a final output layer of 10 nodes. Compile the model with a `categorical_crossentropy` loss, using the SGD optimizer, and the `accuracy` metric. \n",
    "Note that you will need to use the `Flatten` layer first in order to convert the 3D (x, y, rgb) image data into 1D.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48bwK-d3WLWl",
    "outputId": "3e32ab9c-266b-46f8-ede2-cae00af55b98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flattening the dataset inputs\n",
    "X_train_flattened = X_train.reshape(len(X_train), 32*32*3)\n",
    "X_test_flattened = X_test.reshape(len(X_test), 32*32*3)\n",
    "X_test_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlhyUiE-XjJk",
    "outputId": "7ef6750e-2921-4de9-fd54-17dc38dec204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.8483 - accuracy: 0.3365 - val_loss: 1.7821 - val_accuracy: 0.3546\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 1.6463 - accuracy: 0.4129 - val_loss: 1.9162 - val_accuracy: 0.3204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f685e6f0250>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.backend import batch_normalization\n",
    "model=keras.models.Sequential()\n",
    "model.add(Dense(2048, input_shape=(3072,), activation='relu'))\n",
    "keras.layers.BatchNormalization(),\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "keras.layers.BatchNormalization(),\n",
    "model.add(Dense(512, activation='relu'))\n",
    "keras.layers.BatchNormalization(),\n",
    "model.add(Dense(256, activation='relu'))\n",
    "keras.layers.BatchNormalization(),\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcQbyP47WLWl"
   },
   "source": [
    "**7) Compute by hand the total number of trainable parameters (weights and biases) in the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPwP83TQWLWl"
   },
   "source": [
    "*9,050,378*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lT4-q6dWLWl"
   },
   "source": [
    "**8) Use the `summary()` function on model to get a text summary of the model.  Did you compute the number of parameters correctly?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Wav8WypWLWm",
    "outputId": "2f8a6d42-ab26-41f2-8f5a-1b23aed84797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2048)              6293504   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,050,378\n",
      "Trainable params: 9,050,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uozZLSoZWLWm"
   },
   "source": [
    "**9) Train the model:**\n",
    "  - Start with a small batch size of 32 and train for 10 epochs\n",
    "  - Use early stopping on the validation accuracy with a patience of 2 (use 10% of your training set as the validation set)\n",
    "  \n",
    "**How does the model perform?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2WKc2jPTWLWm",
    "outputId": "d936450a-06d3-4ff4-b8a3-b94c13066a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2393 - accuracy: 0.5575\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1993 - accuracy: 0.5745\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1634 - accuracy: 0.5874\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1295 - accuracy: 0.6000\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0927 - accuracy: 0.6120\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0585 - accuracy: 0.6238\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0223 - accuracy: 0.6363\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9867 - accuracy: 0.6485\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9552 - accuracy: 0.6600\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9219 - accuracy: 0.6730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f685e59e6a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_flattened, y_train, epochs=10,batch_size=32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2Wqnb6KZ_yj",
    "outputId": "7752c448-8c8d-4851-8b43-50542af9b26b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8844 - accuracy: 0.6867 - val_loss: 1.2339 - val_accuracy: 0.5774\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.8465 - accuracy: 0.6995 - val_loss: 1.1726 - val_accuracy: 0.5814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f685e5b63a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_flattened, y_train,epochs=10,batch_size=32, validation_split=0.1,callbacks=EarlyStopping(monitor='val_loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUr0XmctWLWm"
   },
   "source": [
    "**10) Try changing the batch size to see if there is any improvement.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOnHB3ZiWLWm",
    "outputId": "1057f310-8834-4dcb-a1f5-7aafffd0cf4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5394 - accuracy: 0.4526\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.4854 - accuracy: 0.4700\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.4374 - accuracy: 0.4889\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.4012 - accuracy: 0.5035\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3629 - accuracy: 0.5184\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3275 - accuracy: 0.5279\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2933 - accuracy: 0.5396\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2637 - accuracy: 0.5515\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2341 - accuracy: 0.5634\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2074 - accuracy: 0.5752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f685e67e520>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_flattened, y_train, epochs=10,batch_size=50 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77fAW3uIWLWn"
   },
   "source": [
    "**11) Try adding batch normalization after each hidden layer.  Any better?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iX2hI-LtWLWn"
   },
   "outputs": [],
   "source": [
    "# I have already added Batch normalization layer, adding batch normalization layer increases the accuracy of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8Z32lwnWLWn"
   },
   "source": [
    "<a id='cnn'></a>\n",
    "\n",
    "# 3 - Convolutional Neural Network\n",
    " \n",
    "\n",
    "Convolutional neural networks allow us to do drastically better on this dataset (and many image classification problems in general). In this task, you will build a convolutional network and see how it performs during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7X_8aSCWLWn"
   },
   "source": [
    "**12) Create a new model with the following layers**\n",
    "  - 3x3 2D convolution with zero padding (same), 32 filters\n",
    "  - ReLU activation\n",
    "  - 3,3 2D convolution, no padding, 32 filters\n",
    "  - ReLU activation\n",
    "  - Max pooling with size (2,2)\n",
    "  - 3x3 2D convolution, no padding, 64 filters\n",
    "  - ReLU activation\n",
    "  - 3x3 2D convolution, no padding, 64 filters\n",
    "  - ReLU activation\n",
    "  - Max pooling with size (2,2)\n",
    "  - Flatten\n",
    "  - Dense layer with 512 nodes, ReLU activation\n",
    "  - Softmax output layer with 10 nodes\n",
    "  \n",
    "**Compile the network with same optimizer and metrics as the dense network.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_3EG4QyWLWn"
   },
   "outputs": [],
   "source": [
    "cnn = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zeix4tUWLWo"
   },
   "source": [
    "**13) Compute by hand the number of trainable parameters in this network.  Are there more or less than the more simple dense network?  Why?  Confirm with `summary()`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CijMq8b_WLWo",
    "outputId": "793e300c-8ea5-4865-c29f-e354130179bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 28, 28, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 10, 10, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 512)               819712    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 892,842\n",
      "Trainable params: 891,626\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qXQjszoa857"
   },
   "outputs": [],
   "source": [
    "# ANN has greater number of trainable parameters as compare to CNN, because we have added layer in ANN that's why layers have increased the number of trainable parameters in simple neural network.(ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCc0L5a-WLWo"
   },
   "source": [
    "**14) Use the same training procedure as before for 10 epochs and batch size of 32. How does the validation accuracy change with each epoch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2LguFeoWLWo",
    "outputId": "19f63d14-f927-4be2-e166-f1c6d6f23750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 16s 5ms/step - loss: 1.5037 - accuracy: 0.4774\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0744 - accuracy: 0.6226\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8987 - accuracy: 0.6864\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8091 - accuracy: 0.7158\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7392 - accuracy: 0.7428\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6704 - accuracy: 0.7627\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6235 - accuracy: 0.7829\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5839 - accuracy: 0.7943\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5577 - accuracy: 0.8044\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5186 - accuracy: 0.8180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6874045370>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=10, batch_size=32 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ka28Alt-WLWo"
   },
   "source": [
    "**15) Increase the batch size to 64 and retrain.  Better or worse?  Try 128 as well.  How does increasing the batch size improve the training?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8x_bFedeWLWo",
    "outputId": "4d36b580-3fdb-4f56-fd22-da4f80f67b33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3691 - accuracy: 0.8700\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3256 - accuracy: 0.8837\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.3072 - accuracy: 0.8903\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2851 - accuracy: 0.8978\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.2619 - accuracy: 0.9061\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.2489 - accuracy: 0.9115\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2316 - accuracy: 0.9153\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.2128 - accuracy: 0.9251\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 7s 10ms/step - loss: 0.2007 - accuracy: 0.9287\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 7s 10ms/step - loss: 0.1870 - accuracy: 0.9336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f685e363490>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=10, batch_size=64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uU7GsTkqcd_M",
    "outputId": "9d068a80-6183-4716-f4fe-b4bb06343711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.1174 - accuracy: 0.9607\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.0989 - accuracy: 0.9670\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.0901 - accuracy: 0.9684\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.0866 - accuracy: 0.9705\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.0877 - accuracy: 0.9701\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.0853 - accuracy: 0.9712\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.0890 - accuracy: 0.9686\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.0841 - accuracy: 0.9699\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.0885 - accuracy: 0.9692\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.0854 - accuracy: 0.9701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f685e374e50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=10, batch_size=128 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz0HXWppWLWp"
   },
   "source": [
    "**16) Note how the validation accuracy begins to decrease at some point, while the training accuracy continues to increase.  What is this phenomena called?  Try adding 3 dropout layers to the model, one before each max pooling layer and one before the last layer, using a dropout ratio of 0.25.  Does this improve the model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHotuFATWLWp"
   },
   "outputs": [],
   "source": [
    "#  Overfitting. Value of accuracy after adding dropout = 0.83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oh_RgY0WLWp"
   },
   "source": [
    "**17) Play with batch normalization.  For example, add batch normalization layers after each dropout layer.  Do you notice a faster increase in the model improvement? Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SUokdGWKWLWp"
   },
   "outputs": [],
   "source": [
    "# Accuracy is 0.88 after adding batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-Jv9xcSWLWq"
   },
   "source": [
    "<a id='results'></a>\n",
    "\n",
    "# 4 - Interpreting the results\n",
    " \n",
    "<a id='results_prediction'></a>\n",
    "\n",
    "## 4.1 - Making predictions\n",
    "\n",
    "Assuming all went well during the previous tasks, you can now predict the category of a new image!  Here are a few examples of my predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRLtXjvCWLWq"
   },
   "source": [
    "![Results.png](attachment:Results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYvHGmpSWLWq"
   },
   "source": [
    "**18) Use `predict` on your trained model to test its prediction on a few example images of the test set. Using `imshow` and `hbar` from `matplotlib.pyplot`, try to recreate the image above for a few example images.**\n",
    "\n",
    "<!---**Hint:** at this point, it is probably convenient to use the `save` and `load_model` functions from Keras.  You can save the model after training it, and then decide to load from saved file instead of building a new one (if available) on successive runs.--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HU4R_qpWWLWr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03jBdUhMWLWr"
   },
   "source": [
    "<a id='results_evaluation'></a>\n",
    "\n",
    "## 4.2 Evaluating the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rct-ggXEWLWr"
   },
   "source": [
    "A confusion matrix is often used in supervised learning to understand how well (or not) each category is being classified.  Each element (i,j) in the confusion matrix represents the predicted class j for each true class i.  Consider the following 10 predictions for a 2 category model predicting male or female:\n",
    "\n",
    "| example     | true category  | predicted category  |\n",
    "|-------------|----------------|---------------------|\n",
    "| 1           | male           | male                |\n",
    "| 2           | female         | male                |\n",
    "| 3           | female         | female              |\n",
    "| 4           | male           | male                |\n",
    "| 5           | male           | female              |\n",
    "| 6           | male           | male                |\n",
    "| 7           | female         | female              |\n",
    "| 8           | male           | female              |\n",
    "| 9           | female         | female              |\n",
    "| 10          | female         | female              |\n",
    "\n",
    "Based on the above data, the model is accurate 70% of the time.  The confusion matrix is\n",
    "\n",
    "|        | male | female |\n",
    "|--------|------|--------|\n",
    "| male   | 3    | 2      |\n",
    "| female | 1    | 4      |\n",
    "\n",
    "The confusion matrix gives us more information than a simple accuracy measurement.  In this case, we see that the class female has a higher accuracy over male.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDe8gL5XWLWr"
   },
   "source": [
    "**19) Create the confusion matrix for the CIFAR-10 dataset using the test data.  What does it tell you about the relationships between each class?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VvyDzmjIWLWs",
    "outputId": "0c4c3321-365e-4df2-8bee-83a6366d912a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      1000\n",
      "           1       0.91      0.88      0.90      1000\n",
      "           2       0.71      0.73      0.72      1000\n",
      "           3       0.62      0.64      0.63      1000\n",
      "           4       0.70      0.80      0.75      1000\n",
      "           5       0.73      0.69      0.71      1000\n",
      "           6       0.78      0.89      0.83      1000\n",
      "           7       0.91      0.77      0.84      1000\n",
      "           8       0.91      0.82      0.86      1000\n",
      "           9       0.91      0.82      0.87      1000\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "y_pred = cnn.predict(X_test)\n",
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y14edMj9WLWs"
   },
   "source": [
    "<a id='pretrained_cnn'></a>\n",
    "# 5 - Improving on current performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kK2P7n1uWLWs"
   },
   "source": [
    "**20) Play with different CNN architectures. Provide a few attempts (atleast 1 and atmost 3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urr6cdl_WLWt",
    "outputId": "fd818d32-b576-403a-9675-863ddf67fbe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 43)                3655      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,511\n",
      "Trainable params: 64,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 20) LeNet_CNN\n",
    "LeNet = keras.models.Sequential()\n",
    "\n",
    "LeNet.add(keras.layers.Conv2D(6, (5,5), activation = 'relu', input_shape= (32,32,1)))\n",
    "LeNet.add(keras.layers.AveragePooling2D())\n",
    "\n",
    "LeNet.add(keras.layers.Conv2D(16, (5,5), activation = 'relu'))\n",
    "LeNet.add(keras.layers.AveragePooling2D())\n",
    "\n",
    "LeNet.add(keras.layers.Flatten())\n",
    "\n",
    "LeNet.add(keras.layers.Dense(120, activation='relu'))\n",
    "\n",
    "LeNet.add(keras.layers.Dense(84, activation='relu'))\n",
    "\n",
    "LeNet.add(keras.layers.Dense(43, activation='softmax'))\n",
    "LeNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DxNAlFnWLWt"
   },
   "source": [
    "Note that several pre-trained networks are directly accessible via keras (see https://nbviewer.jupyter.org/github/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
